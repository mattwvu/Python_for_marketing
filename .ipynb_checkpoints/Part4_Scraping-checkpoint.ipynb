{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8176f1-ebf1-4605-bd26-beddc3f77341",
   "metadata": {},
   "source": [
    "<h1>Web Scraping with Beautiful Soup</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a15b3-d479-441b-a91a-aef69e3363d1",
   "metadata": {},
   "source": [
    "<h3>Basic HTML Structure</h3>\n",
    "<p>Basic HTML Tags:</p>\n",
    "<p><ul>\n",
    "    <li>html, head, body </li>\n",
    "    <li>div, a, p, h1, ul </li> \n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c457699-5488-4cf3-8124-5039f144f5d9",
   "metadata": {},
   "source": [
    "<h3>Viewing HTML Source:</h3>\n",
    "<p><ul>\n",
    "    <li>Right-click on a webpage</li>\n",
    "    <li>Select \"View Page Source\"</li>\n",
    "\n",
    "</ul></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462610a-8754-419c-91b2-f7b42391908e",
   "metadata": {},
   "source": [
    "<h2>Beautiful Soup</h2>\n",
    "<p><a href=\"https://pypi.org/project/beautifulsoup4/\">https://pypi.org/project/beautifulsoup4/</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a26bf-ee26-4a20-8598-d014817b28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561cb2e0-d2ad-43ea-bf40-b2334d1ce4a0",
   "metadata": {},
   "source": [
    "<h3>Scrap Yelp</h3>\n",
    "<p><a href = \"https://www.yelp.com/biz/stone-tower-brews-morgantown\">https://www.yelp.com/biz/stone-tower-brews-morgantown</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3407f-62c8-4ff8-85e1-da1682b55dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://www.yelp.com/biz/stone-tower-brews-morgantown'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba49ea95-84e9-4c34-b714-9e534ab4ee2b",
   "metadata": {},
   "source": [
    "<h3>Extracting the Review</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb554ebf-0ebd-41d9-bb58-a67f051efce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find_all('li', class_='y-css-1jp2syp')\n",
    "for review in reviews:\n",
    "    print(review.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358895e8-00dc-4cae-9a69-ddee32cdb1c7",
   "metadata": {},
   "source": [
    "<h3>Extracting Elements of the Review</h3>\n",
    "<p>Elements:</p>\n",
    "<ul>\n",
    "    <li>Reviewer</li>\n",
    "    <li>Rating</li>\n",
    "    <li>Text</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0eaf4321-5ebd-437d-81dc-a4c548ae7c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date      Username Rating  \\\n",
      "0    Dec 7, 2023    Heather M.      5   \n",
      "1   May 25, 2023       Erin p.      5   \n",
      "2   Jan 20, 2024      David D.      1   \n",
      "3   Oct 30, 2023       Mark R.      5   \n",
      "4   Jul 29, 2023          A B.      5   \n",
      "5    Mar 3, 2024       Lisa L.      1   \n",
      "6   Dec 29, 2023      Allie H.      4   \n",
      "7    Mar 1, 2024  Stephanie E.      5   \n",
      "8   Oct 17, 2023         Ed L.      5   \n",
      "9   Jan 13, 2024     Andrew C.      5   \n",
      "10  Nov 11, 2023       Rick P.      5   \n",
      "11   Feb 4, 2024       Neva S.      5   \n",
      "12   Sep 7, 2023      Becca F.      3   \n",
      "13   Jan 9, 2024     Brooke L.      5   \n",
      "14  Mar 24, 2024      Katie B.      3   \n",
      "\n",
      "                                               Review  \n",
      "0   I've eaten breakfast, lunch and dinner at this...  \n",
      "1   Awesome new cafe in Morgantown!  Food was deli...  \n",
      "2   today I had yet another rude interaction from ...  \n",
      "3   excellent selection great staff and venue park...  \n",
      "4   This place is so cool! It's like a Starbucks w...  \n",
      "5   Wow. Wow. Wow. Where to begin? The space is we...  \n",
      "6   Whether you want coffee or beer, this place ha...  \n",
      "7   Super cute coffee spot located in a plaza with...  \n",
      "8   I went there to take some photos and do some e...  \n",
      "9   Yummy food, good coffee, friendly service, nic...  \n",
      "10  Good coffee, atmosphere was conducive to study...  \n",
      "11  Holy cow Batman! I love this place! Sugar free...  \n",
      "12  Pros:The location is great for this area. The ...  \n",
      "13  I had heard wonderful things about this place ...  \n",
      "14  Always feel confused and rushed when ordering....  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URLs of the pages containing reviews\n",
    "reviewer_urls = [\n",
    "    \"https://www.yelp.com/biz/stone-tower-brews-morgantown?start=10\",\n",
    "    \"https://www.yelp.com/biz/stone-tower-brews-morgantown\"\n",
    "]\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "usernames = []\n",
    "ratings = []\n",
    "reviews = []\n",
    "dates = []  # List to store dates\n",
    "\n",
    "for url in reviewer_urls:\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all review containers\n",
    "    review_containers = soup.find_all('li', class_='y-css-1jp2syp')\n",
    "\n",
    "    # Extracting the date\n",
    "    for review_container in review_containers:\n",
    "        # find the element containing the date\n",
    "        date_element = review_container.find('span', class_='y-css-wfbtsu')\n",
    "        if date_element:\n",
    "            date = date_element.text.strip()\n",
    "        else:\n",
    "            date = \"NA\"\n",
    "        dates.append(date)\n",
    "\n",
    "    # Iterate over each review container\n",
    "    for review_container in review_containers:\n",
    "        # Find the element containing the username\n",
    "        user_element = review_container.find('span', class_='y-css-w3ea6v')\n",
    "        if user_element:\n",
    "            username = user_element.text.strip()\n",
    "        else:\n",
    "            username = \"NA\"\n",
    "        usernames.append(username)\n",
    "\n",
    "        # Find the element containing the rating within the review container\n",
    "        rating_element = review_container.find('div', role='img')\n",
    "\n",
    "        # Extract the rating from the aria-label attribute if it exists\n",
    "        if rating_element and 'aria-label' in rating_element.attrs:\n",
    "            rating = rating_element['aria-label'].split()[0]\n",
    "        else:\n",
    "            rating = \"NA\"\n",
    "        ratings.append(rating)\n",
    "\n",
    "        # Find the element containing the review\n",
    "        review_element = review_container.find('p', class_='comment__09f24__D0cxf y-css-h9c2fl')\n",
    "        if review_element:\n",
    "            review = review_element.text.strip()\n",
    "        else:\n",
    "            review = \"NA\"\n",
    "        reviews.append(review)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "data = {'Date': dates, 'Username': usernames, 'Rating': ratings, 'Review': reviews}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Export the DataFrame\n",
    "df.to_csv(\"stone_tower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc7faaba-578d-4c13-a48c-543073041a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date      Username Rating  \\\n",
      "0    Dec 7, 2023    Heather M.      5   \n",
      "1   May 25, 2023       Erin p.      5   \n",
      "2   Jan 20, 2024      David D.      1   \n",
      "3   Oct 30, 2023       Mark R.      5   \n",
      "4   Jul 29, 2023          A B.      5   \n",
      "5    Mar 3, 2024       Lisa L.      1   \n",
      "6   Dec 29, 2023      Allie H.      4   \n",
      "7    Mar 1, 2024  Stephanie E.      5   \n",
      "8   Oct 17, 2023         Ed L.      5   \n",
      "9   Jan 13, 2024     Andrew C.      5   \n",
      "10  Nov 11, 2023       Rick P.      5   \n",
      "11   Feb 4, 2024       Neva S.      5   \n",
      "12   Sep 7, 2023      Becca F.      3   \n",
      "13   Jan 9, 2024     Brooke L.      5   \n",
      "14  Mar 24, 2024      Katie B.      3   \n",
      "\n",
      "                                               Review  \n",
      "0   I've eaten breakfast, lunch and dinner at this...  \n",
      "1   Awesome new cafe in Morgantown!  Food was deli...  \n",
      "2   today I had yet another rude interaction from ...  \n",
      "3   excellent selection great staff and venue park...  \n",
      "4   This place is so cool! It's like a Starbucks w...  \n",
      "5   Wow. Wow. Wow. Where to begin? The space is we...  \n",
      "6   Whether you want coffee or beer, this place ha...  \n",
      "7   Super cute coffee spot located in a plaza with...  \n",
      "8   I went there to take some photos and do some e...  \n",
      "9   Yummy food, good coffee, friendly service, nic...  \n",
      "10  Good coffee, atmosphere was conducive to study...  \n",
      "11  Holy cow Batman! I love this place! Sugar free...  \n",
      "12  Pros:The location is great for this area. The ...  \n",
      "13  I had heard wonderful things about this place ...  \n",
      "14  Always feel confused and rushed when ordering....  \n"
     ]
    }
   ],
   "source": [
    "# create a function for scraping\n",
    "\n",
    "def yelp_scrap():\n",
    "\n",
    "    # Initialize lists to store extracted data\n",
    "    usernames = []\n",
    "    ratings = []\n",
    "    reviews = []\n",
    "    dates = []  # List to store dates\n",
    "    \n",
    "    for url in reviewer_urls:\n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all review containers\n",
    "        review_containers = soup.find_all('li', class_='y-css-1jp2syp')\n",
    "\n",
    "        # Extracting the date\n",
    "        for review_container in review_containers:\n",
    "            # find the element containing the date\n",
    "            date_element = review_container.find('span', class_='y-css-wfbtsu')\n",
    "            if date_element:\n",
    "                date = date_element.text.strip()\n",
    "            else:\n",
    "                date = \"NA\"\n",
    "            dates.append(date)\n",
    "\n",
    "        # Iterate over each review container\n",
    "        for review_container in review_containers:\n",
    "            # Find the element containing the username\n",
    "            user_element = review_container.find('span', class_='y-css-w3ea6v')\n",
    "            username = user_element.text.strip()\n",
    "            usernames.append(username)\n",
    "\n",
    "            # Find the element containing the rating within the review container\n",
    "            rating_element = review_container.find('div', role='img')\n",
    "\n",
    "            # Extract the rating from the aria-label attribute if it exists\n",
    "            if rating_element and 'aria-label' in rating_element.attrs:\n",
    "                rating = rating_element['aria-label'].split()[0]\n",
    "            else:\n",
    "                rating = \"NA\"\n",
    "            ratings.append(rating)\n",
    "\n",
    "            # Find the element containing the review\n",
    "            review_element = review_container.find('p', class_='comment__09f24__D0cxf y-css-h9c2fl')\n",
    "            review = review_element.text.strip()\n",
    "            reviews.append(review)\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    data = {'Date': dates, 'Username': usernames, 'Rating': ratings, 'Review': reviews}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a8a30f3-cabf-466c-9b47-0fe3c7e392d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date   Username Rating  \\\n",
      "0  Aug 23, 2023     Eli J.      5   \n",
      "1  Mar 23, 2023  Kelsey R.      5   \n",
      "\n",
      "                                              Review  \n",
      "0  Stopped here for the first time. Small place w...  \n",
      "1  I was driving down University Avenue in Morgan...  \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URLs of the pages containing reviews\n",
    "reviewer_urls = [\n",
    "    \"https://www.yelp.com/biz/stray-cat-chimmi-shack-morgantown\"\n",
    "]\n",
    "\n",
    "\n",
    "yelp_scrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daaa4ca-d122-4be8-b7de-713278714012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the DataFrame\n",
    "\n",
    "df.to_csv(\"stray_cat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a5c68bdf-b84f-44c9-b4df-f28b81cca85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def yelp_scrap(base_url, num_pages, csv_filename=None):\n",
    "    # Initialize lists to store extracted data\n",
    "    usernames = []\n",
    "    ratings = []\n",
    "    reviews = []\n",
    "    dates = []  # List to store dates\n",
    "    \n",
    "    for page_num in range(num_pages):\n",
    "        # Generate the URL for the current page\n",
    "        url = f\"{base_url}?start={page_num * 10}\"\n",
    "        \n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        # Find all review containers\n",
    "        review_containers = soup.find_all('li', class_='y-css-1jp2syp')\n",
    "        \n",
    "        # Iterate over each review container\n",
    "        for review_container in review_containers:\n",
    "            # Find the element containing the username\n",
    "            user_element = review_container.find('span', class_='y-css-w3ea6v')\n",
    "            username = user_element.text.strip() if user_element else 'N/A'\n",
    "            usernames.append(username)\n",
    "    \n",
    "            # Find the element containing the rating within the review container\n",
    "            rating_element = review_container.find('div', role='img')\n",
    "    \n",
    "            # Extract the rating from the aria-label attribute if it exists\n",
    "            if rating_element and 'aria-label' in rating_element.attrs:\n",
    "                rating = rating_element['aria-label'].split()[0]\n",
    "            else:\n",
    "                rating = \"NA\"\n",
    "            ratings.append(rating)\n",
    "    \n",
    "            # Find the element containing the review\n",
    "            review_element = review_container.find('p', class_='comment__09f24__D0cxf')\n",
    "            review = review_element.text.strip() if review_element else 'N/A'\n",
    "            reviews.append(review)\n",
    "            \n",
    "            # Find the element containing the date\n",
    "            date_element = review_container.find('span', class_='y-css-wfbtsu')\n",
    "            date = date_element.text.strip() if date_element else 'N/A'\n",
    "            dates.append(date)\n",
    "    \n",
    "    # Create a DataFrame from the extracted data\n",
    "    data = {'Date': dates, 'Username': usernames, 'Rating': ratings, 'Review': reviews}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "    \n",
    "    # Export to CSV if filename is provided\n",
    "    if csv_filename:\n",
    "        df.to_csv(csv_filename, index=False, header = True)\n",
    "        print(f\"Data exported to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2581221f-d7f5-4f7f-9e86-8180bb7c35db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Date     Username Rating  \\\n",
      "0             N/A          N/A     NA   \n",
      "1    Nov 16, 2023    Donald F.      5   \n",
      "2     May 3, 2024  Marianne D.      3   \n",
      "3    Jul 29, 2023    Brooke T.      1   \n",
      "4    Feb 17, 2024      Sara L.      3   \n",
      "..            ...          ...    ...   \n",
      "104  Aug 15, 2013     Jimmy G.      5   \n",
      "105   Feb 9, 2015    Sharon M.      1   \n",
      "106  Dec 22, 2016         S M.      3   \n",
      "107   Oct 1, 2014         J L.      1   \n",
      "108  May 16, 2016      Pete C.      5   \n",
      "\n",
      "                                                Review  \n",
      "0                                                  N/A  \n",
      "1    Went up to see the daughter in Morgantown! Wan...  \n",
      "2    The bartender was amazing and he made really g...  \n",
      "3    Shown are the appetizers of Cheesy Nachos with...  \n",
      "4    We walked in and immediately felt under dresse...  \n",
      "..                                                 ...  \n",
      "104  What a great find in Morgantown! Upscale marti...  \n",
      "105  Spent two nights at the Hilton Garden Inn. Cou...  \n",
      "106  I have come here many many times.  Usually the...  \n",
      "107  The owner pulled a fast one and changed happy ...  \n",
      "108  I went to Bartini this past weekend following ...  \n",
      "\n",
      "[109 rows x 4 columns]\n",
      "Data exported to bartini_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "# add your own yelp page here \n",
    "\n",
    "# Base URL of the restaurant's Yelp page\n",
    "base_url = \"https://www.yelp.com/biz/bartini-prime-morgantown\"\n",
    "\n",
    "# Number of pages to scrape (adjust as needed)\n",
    "num_pages = 11\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"bartini_reviews.csv\"\n",
    "\n",
    "# Call the function with export option\n",
    "yelp_scrap(base_url, num_pages, csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf9d2a-edad-421d-9df1-01ac77fb0813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
