{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8176f1-ebf1-4605-bd26-beddc3f77341",
   "metadata": {},
   "source": [
    "<h1>Web Scraping with Beautiful Soup</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a15b3-d479-441b-a91a-aef69e3363d1",
   "metadata": {},
   "source": [
    "<h3>Basic HTML Structure</h3>\n",
    "<p>Basic HTML Tags:</p>\n",
    "<p><ul>\n",
    "    <li>html, head, body </li>\n",
    "    <li>div, a, p, h1, ul </li> \n",
    "</ul></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c457699-5488-4cf3-8124-5039f144f5d9",
   "metadata": {},
   "source": [
    "<h3>Viewing HTML Source:</h3>\n",
    "<p><ul>\n",
    "    <li>Right-click on a webpage</li>\n",
    "    <li>Select \"View Page Source\"</li>\n",
    "\n",
    "</ul></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462610a-8754-419c-91b2-f7b42391908e",
   "metadata": {},
   "source": [
    "<h2>Beautiful Soup</h2>\n",
    "<p><a href=\"https://pypi.org/project/beautifulsoup4/\">https://pypi.org/project/beautifulsoup4/</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a26bf-ee26-4a20-8598-d014817b28b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da77a30-9f1f-431c-a6c0-739cf0394545",
   "metadata": {},
   "source": [
    "<h3>Requests</h3>\n",
    "<p><a href =\"https://pypi.org/project/requests/\">https://pypi.org/project/requests/</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5cf53-66fc-4553-b1a8-fc33267a698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561cb2e0-d2ad-43ea-bf40-b2334d1ce4a0",
   "metadata": {},
   "source": [
    "<h3>Scrap Yelp</h3>\n",
    "<p><a href = \"https://www.yelp.com/biz/stone-tower-brews-morgantown\">https://www.yelp.com/biz/stone-tower-brews-morgantown</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa3407f-62c8-4ff8-85e1-da1682b55dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://www.yelp.com/biz/stone-tower-brews-morgantown'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba49ea95-84e9-4c34-b714-9e534ab4ee2b",
   "metadata": {},
   "source": [
    "<h3>Extracting the Review</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb554ebf-0ebd-41d9-bb58-a67f051efce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find_all('li', class_='y-css-1jp2syp')\n",
    "for review in reviews:\n",
    "    print(review.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358895e8-00dc-4cae-9a69-ddee32cdb1c7",
   "metadata": {},
   "source": [
    "<h3>Extracting Elements of the Review</h3>\n",
    "<p>Elements:</p>\n",
    "<ul>\n",
    "    <li>Reviewer</li>\n",
    "    <li>Rating</li>\n",
    "    <li>Text</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf4321-5ebd-437d-81dc-a4c548ae7c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URLs of the pages containing reviews\n",
    "reviewer_urls = [\n",
    "    \"https://www.yelp.com/biz/stone-tower-brews-morgantown?start=10\",\n",
    "    \"https://www.yelp.com/biz/stone-tower-brews-morgantown\"\n",
    "]\n",
    "\n",
    "# Initialize lists to store extracted data\n",
    "usernames = []\n",
    "ratings = []\n",
    "reviews = []\n",
    "dates = [] \n",
    "\n",
    "for url in reviewer_urls:\n",
    "    # Fetch the webpage content\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all review containers\n",
    "    review_containers = soup.find_all('li', class_='y-css-1jp2syp')\n",
    "\n",
    "    # Extracting the date\n",
    "    for review_container in review_containers:\n",
    "        # find the element containing the date\n",
    "        date_element = review_container.find('span', class_='y-css-wfbtsu')\n",
    "        if date_element:\n",
    "            date = date_element.text.strip()\n",
    "        else:\n",
    "            date = \"NA\"\n",
    "        dates.append(date)\n",
    "\n",
    "    # Iterate over each review container\n",
    "    for review_container in review_containers:\n",
    "        # Find the element containing the username\n",
    "        user_element = review_container.find('span', class_='y-css-w3ea6v')\n",
    "        if user_element:\n",
    "            username = user_element.text.strip()\n",
    "        else:\n",
    "            username = \"NA\"\n",
    "        usernames.append(username)\n",
    "\n",
    "        # Find the element containing the rating within the review container\n",
    "        rating_element = review_container.find('div', role='img')\n",
    "\n",
    "        # Extract the rating from the aria-label attribute if it exists\n",
    "        if rating_element and 'aria-label' in rating_element.attrs:\n",
    "            rating = rating_element['aria-label'].split()[0]\n",
    "        else:\n",
    "            rating = \"NA\"\n",
    "        ratings.append(rating)\n",
    "\n",
    "        # Find the element containing the review\n",
    "        review_element = review_container.find('p', class_='comment__09f24__D0cxf y-css-h9c2fl')\n",
    "        if review_element:\n",
    "            review = review_element.text.strip()\n",
    "        else:\n",
    "            review = \"NA\"\n",
    "        reviews.append(review)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "data = {'Date': dates, 'Username': usernames, 'Rating': ratings, 'Review': reviews}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Export the DataFrame\n",
    "df.to_csv(\"stone_tower.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7faaba-578d-4c13-a48c-543073041a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for scraping\n",
    "\n",
    "def yelp_scrap():\n",
    "\n",
    "    # Initialize lists to store extracted data\n",
    "    usernames = []\n",
    "    ratings = []\n",
    "    reviews = []\n",
    "    dates = []  \n",
    "    \n",
    "    for url in reviewer_urls:\n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all review containers\n",
    "        review_containers = soup.find_all('li', class_='y-css-1jp2syp')\n",
    "\n",
    "        # Extracting the date\n",
    "        for review_container in review_containers:\n",
    "            # find the element containing the date\n",
    "            date_element = review_container.find('span', class_='y-css-wfbtsu')\n",
    "            if date_element:\n",
    "                date = date_element.text.strip()\n",
    "            else:\n",
    "                date = \"NA\"\n",
    "            dates.append(date)\n",
    "\n",
    "        # Iterate over each review container\n",
    "        for review_container in review_containers:\n",
    "            # Find the element containing the username\n",
    "            user_element = review_container.find('span', class_='y-css-w3ea6v')\n",
    "            username = user_element.text.strip()\n",
    "            usernames.append(username)\n",
    "\n",
    "            # Find the element containing the rating within the review container\n",
    "            rating_element = review_container.find('div', role='img')\n",
    "\n",
    "            # Extract the rating from the aria-label attribute if it exists\n",
    "            if rating_element and 'aria-label' in rating_element.attrs:\n",
    "                rating = rating_element['aria-label'].split()[0]\n",
    "            else:\n",
    "                rating = \"NA\"\n",
    "            ratings.append(rating)\n",
    "\n",
    "            # Find the element containing the review\n",
    "            review_element = review_container.find('p', class_='comment__09f24__D0cxf y-css-h9c2fl')\n",
    "            review = review_element.text.strip()\n",
    "            reviews.append(review)\n",
    "\n",
    "    # Create a DataFrame from the extracted data\n",
    "    data = {'Date': dates, 'Username': usernames, 'Rating': ratings, 'Review': reviews}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Print the DataFrame\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a30f3-cabf-466c-9b47-0fe3c7e392d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URLs of the pages containing reviews\n",
    "reviewer_urls = [\n",
    "    \"https://www.yelp.com/biz/stray-cat-chimmi-shack-morgantown\"\n",
    "]\n",
    "\n",
    "\n",
    "yelp_scrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daaa4ca-d122-4be8-b7de-713278714012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the DataFrame\n",
    "\n",
    "df.to_csv(\"stray_cat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c68bdf-b84f-44c9-b4df-f28b81cca85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def yelp_scrap(base_url, num_pages, csv_filename=None):\n",
    "    # Initialize lists to store extracted data\n",
    "    usernames = []\n",
    "    ratings = []\n",
    "    reviews = []\n",
    "    dates = []  \n",
    "    \n",
    "    for page_num in range(num_pages):\n",
    "        # Generate the URL for the current page\n",
    "        url = f\"{base_url}?start={page_num * 10}\"\n",
    "        \n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "        # Find all review containers\n",
    "        review_containers = soup.find_all('li', class_='y-css-1jp2syp')\n",
    "        \n",
    "        # Iterate over each review container\n",
    "        for review_container in review_containers:\n",
    "            # Find the element containing the username\n",
    "            user_element = review_container.find('span', class_='y-css-w3ea6v')\n",
    "            username = user_element.text.strip() if user_element else 'N/A'\n",
    "            usernames.append(username)\n",
    "    \n",
    "            # Find the element containing the rating within the review container\n",
    "            rating_element = review_container.find('div', role='img')\n",
    "    \n",
    "            # Extract the rating from the aria-label attribute if it exists\n",
    "            if rating_element and 'aria-label' in rating_element.attrs:\n",
    "                rating = rating_element['aria-label'].split()[0]\n",
    "            else:\n",
    "                rating = \"NA\"\n",
    "            ratings.append(rating)\n",
    "    \n",
    "            # Find the element containing the review\n",
    "            review_element = review_container.find('p', class_='comment__09f24__D0cxf')\n",
    "            review = review_element.text.strip() if review_element else 'N/A'\n",
    "            reviews.append(review)\n",
    "            \n",
    "            # Find the element containing the date\n",
    "            date_element = review_container.find('span', class_='y-css-wfbtsu')\n",
    "            date = date_element.text.strip() if date_element else 'N/A'\n",
    "            dates.append(date)\n",
    "    \n",
    "    # Create a DataFrame from the extracted data\n",
    "    data = {'Date': dates, 'Username': usernames, 'Rating': ratings, 'Review': reviews}\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(df)\n",
    "    \n",
    "    # Export to CSV if filename is provided\n",
    "    if csv_filename:\n",
    "        df.to_csv(csv_filename, index=False, header = True)\n",
    "        print(f\"Data exported to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581221f-d7f5-4f7f-9e86-8180bb7c35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your own yelp page here \n",
    "\n",
    "# Base URL of the restaurant's Yelp page\n",
    "base_url = \"https://www.yelp.com/biz/bartini-prime-morgantown\"\n",
    "\n",
    "# Number of pages to scrape (adjust as needed)\n",
    "num_pages = 11\n",
    "\n",
    "# CSV filename\n",
    "csv_filename = \"bartini_reviews.csv\"\n",
    "\n",
    "# Call the function with export option\n",
    "yelp_scrap(base_url, num_pages, csv_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
